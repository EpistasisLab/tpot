{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "There are two evolutionary algorithms built into TPOT2, which corresponds to two different estimator classes.\n",
    "\n",
    "1. The `tpot2.TPOTEstimator` uses a standard evolutionary algorithm that evaluates exactly population_size individuals each generation. This is similar to the algorithm in TPOT1. The next generation does not start until the previous is completely finished evaluating. This leads to underutilized CPU time as the cores are waiting for the last individuals to finish training, but may preserve diversity in the population. \n",
    "\n",
    "2. The `tpot2.TPOTEstimatorSteadyState` differs in that it will generate and evaluate the next individual as soon as an individual finishes evaluation. The number of individuals being evaluated is determined by the n_jobs parameter. There is no longer a concept of generations. The population_size parameter now refers to the size of the list of evaluated parents. When an individual is evaluated, the selection method updates the list of parents. This allows more efficient utilization when using multiple cores.\n",
    "\n",
    "\n",
    "Additionally, two other simplified estimators are provided. These have a simplified set of hyperparameters with default values set for classification and regression problems. Currently, both of these use the standard evolutionary algorithm in the `tpot2.TPOTEstimator` class.\n",
    "\n",
    "1. `tpot2.TPOTClassifier` for classification tasks\n",
    "2. `tpot2.TPOTRegressor` for regression tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scorers, Objective Functions, and multi objective optimization.\n",
    "\n",
    "There are two ways of passing objectives into TPOT2. \n",
    "\n",
    "1. `scorers`: Scorers are functions that have the signature (estimator, X, y). These can be produced with the [sklearn.metrics.make_scorer](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) function. This function is used to evaluate the test folds during cross validation. These are passed into TPOT2 via the scorers parameter. This can take in the scorer itself or the string corresponding to a scoring function ([as listed here](https://scikit-learn.org/stable/modules/model_evaluation.html)). TPOT2 also supports passing in a list of several scorers for multiobjective optimization. \n",
    "\n",
    "2. `other_objective_functions` : Other objective functions in TPOT2 have the signature (estimator) and returns a float or list of floats. These get passed an unfitted estimator (in the case of TPOT2, a `tpot2.GraphPipeline`). \n",
    "\n",
    "\n",
    "Each scorer and objective function must be accompanied by a list of weights corresponding to the list of objectives. By default, TPOT2 maximizes objective functions (this can be changed by `bigger_is_better=False`). Positive weights means that TPOT2 will seek to maximize that objective, and negative weights correspond to minimization.\n",
    "\n",
    "Here is an example of using two scorers\n",
    "\n",
    "    scorers=['roc_auc_ovr',tpot2.objectives.complexity_scorer],\n",
    "    scorers_weights=[1,-1],\n",
    "\n",
    "\n",
    "Here is an example with a scorer and a secondary objective function\n",
    "\n",
    "    scorers=['roc_auc_ovr'],\n",
    "    scorers_weights=[1],\n",
    "    other_objective_functions=[tpot2.objectives.number_of_leaves_objective],\n",
    "    other_objective_functions_weights=[-1],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation: : 0it [00:00, ?it/s]/home/ribeirop/common/Projects/TPOT_Dev/tpot2/tpot2/population.py:204: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.9987673084964015, 0.9847336570645737, 0.9905041856662168, 0.9993763441765191, 0.9907964721472181, 0.9972029119373254, 0.998357673885215, 0.9990613894532178, 0.9694329382784964, 0.997532770251522, 0.9975246891516141, 0.9904661635101079, 0.5, 'INVALID', 0.9948797140575193, 0.5, 0.9849666992163886, 0.9824262822238007, 0.9985479308254266, 0.9972915114620106, 0.9694329382784964, 'INVALID', 0.9324417946451, 0.9901685392720255, 0.9978183481741485, 0.9973644125394717, 0.9905750509316356, 0.9819493383116706, 0.9699621501061083, 0.6072655018077077, 0.9694329382784964, 0.9838996235635504, 0.982122385127114, 0.9901266523287818, 0.9301526525124777, 0.9720743554304064, 0.994576960473181, 0.5, 0.5, 0.9948330115435265, 0.9990358447113457, 0.9945434259359371, 0.9375978779782033, 0.9993887714241577, 0.997164111114518, 'INVALID', 'INVALID', 0.9493406027781374, 0.9767172486252121, 0.9974530907820837]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.evaluated_individuals.loc[key,column_names] = data\n",
      "Generation: : 1it [00:14, 14.92s/it]/home/ribeirop/common/Projects/TPOT_Dev/tpot2/tpot2/population.py:381: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'ind_mutate' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.evaluated_individuals.at[new_child.unique_id(),\"Variation_Function\"] = var_op\n",
      "Generation: : 4it [01:19, 19.94s/it]\n",
      "/home/ribeirop/miniconda3/envs/tpot2env/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 0 32 39] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/ribeirop/miniconda3/envs/tpot2env/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999588595957566\n"
     ]
    }
   ],
   "source": [
    "import tpot2\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "scorer = sklearn.metrics.get_scorer('roc_auc_ovo')\n",
    "X, y = sklearn.datasets.load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "\n",
    "\n",
    "est = tpot2.TPOTClassifier(n_jobs=4, max_time_seconds=60, verbose=2)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(scorer(est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation: : 1it [00:03,  3.46s/it]/home/ribeirop/common/Projects/TPOT_Dev/tpot2/tpot2/population.py:381: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'ind_mutate' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.evaluated_individuals.at[new_child.unique_id(),\"Variation_Function\"] = var_op\n",
      "/home/ribeirop/common/Projects/TPOT_Dev/tpot2/tpot2/population.py:204: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['INVALID', -6039.425686838566, -3697.10004861336, -3609.502376363637, -5283.160282257095, -3081.9675902170966, -3159.936813075531, -6.206059150347736e+26, -2983.0962978018993, -3310.997549085264, -3255.911452949286, -3437.783411085481, -6124.753602783256, -2983.0962978018993, 'INVALID', -2951.7123134502217, -3172.715957996382, -3203.3174204236266, -3172.204242312273, -3132.3227284760787, -2904.2526718694835, 'INVALID', 'INVALID', -3065.7604709862753, -2887.332924732963, -3746.3702654907283, -4323.858875859902, -3277.5596662104786, -3687.211654454998, -3801.6275361827234, -3635.7122609143, -3657.0684867411182, -6050.448478793622, -3272.2301971831594, 'INVALID', 'INVALID', -3507.5157340117594, -3291.107812406151, -3673.8549030697295, 'INVALID', -3455.0876361736764, 'INVALID', -3201.783121939595, -2912.050142543978, -3808.6567781967847, 'INVALID', 'INVALID', -2895.0114530615692, -2947.503341616811, -3662.3274712695893]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.evaluated_individuals.loc[key,column_names] = data\n",
      "Generation: : 9it [00:32,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3453.3557493847698\n"
     ]
    }
   ],
   "source": [
    "import tpot2\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "\n",
    "scorer = sklearn.metrics.get_scorer('neg_mean_squared_error')\n",
    "X, y = sklearn.datasets.load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "\n",
    "est = tpot2.tpot_estimator.templates.TPOTRegressor(n_jobs=4, max_time_seconds=30, verbose=2)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "print(scorer(est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices\n",
    "\n",
    "When running tpot from an .py script, it is important to protect code with `if __name__==\"__main__\":`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_analysis.py\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import tpot2\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    scorer = sklearn.metrics.get_scorer('roc_auc_ovo')\n",
    "    X, y = sklearn.datasets.load_digits(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "\n",
    "\n",
    "    est = tpot2.TPOTClassifier(n_jobs=4, max_time_seconds=60, verbose=2)\n",
    "    est.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print(scorer(est, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common parameters\n",
    "\n",
    "        scorers : (list, scorer)\n",
    "            A scorer or list of scorers to be used in the cross-validation process. \n",
    "            see https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "        \n",
    "        scorers_weights : list\n",
    "            A list of weights to be applied to the scorers during the optimization process.\n",
    "        \n",
    "        classification : bool\n",
    "            If True, the problem is treated as a classification problem. If False, the problem is treated as a regression problem.\n",
    "            Used to determine the CV strategy.\n",
    "        \n",
    "        cv : int, cross-validator\n",
    "            - (int): Number of folds to use in the cross-validation process. By uses the sklearn.model_selection.KFold cross-validator for regression and StratifiedKFold for classification. In both cases, shuffled is set to True.\n",
    "            - (sklearn.model_selection.BaseCrossValidator): A cross-validator to use in the cross-validation process.\n",
    "                - max_depth (int): The maximum depth from any node to the root of the pipelines to be generated.\n",
    "        \n",
    "        other_objective_functions : list, default=[tpot2.objectives.estimator_objective_functions.average_path_length_objective]\n",
    "            A list of other objective functions to apply to the pipeline.\n",
    "        \n",
    "        other_objective_functions_weights : list, default=[-1]\n",
    "            A list of weights to be applied to the other objective functions.\n",
    "        \n",
    "        objective_function_names : list, default=None\n",
    "            A list of names to be applied to the objective functions. If None, will use the names of the objective functions.\n",
    "        \n",
    "        bigger_is_better : bool, default=True\n",
    "            If True, the objective function is maximized. If False, the objective function is minimized. Use negative weights to reverse the direction.\n",
    "        \n",
    "        generations : int, default=50\n",
    "            Number of generations to run\n",
    "            \n",
    "        max_time_seconds : float, default=float(\"inf\")\n",
    "            Maximum time to run the optimization. If none or inf, will run until the end of the generations.\n",
    "        \n",
    "        max_eval_time_seconds : float, default=60*5\n",
    "            Maximum time to evaluate a single individual. If none or inf, there will be no time limit per evaluation.\n",
    "\n",
    "        n_jobs : int, default=1\n",
    "            Number of processes to run in parallel.\n",
    "        \n",
    "        memory_limit : str, default=\"4GB\"\n",
    "            Memory limit for each job. See Dask [LocalCluster documentation](https://distributed.dask.org/en/stable/api.html#distributed.Client) for more information.\n",
    "\n",
    "            \n",
    "        verbose : int, default=1 \n",
    "            How much information to print during the optimization process. Higher values include the information from lower values.\n",
    "            0. nothing\n",
    "            1. progress bar\n",
    "            \n",
    "            3. best individual\n",
    "            4. warnings\n",
    "            >=5. full warnings trace\n",
    "            6. evaluations progress bar. (Temporary: This used to be 2. Currently, using evaluation progress bar may prevent some instances were we terminate a generation early due to it reaching max_time_seconds in the middle of a generation OR a pipeline failed to be terminated normally and we need to manually terminate it.)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOTEstimator and TPOTEstimatorSteadyState\n",
    "\n",
    "TPOTEstimator and TPOTEstimatorSteadyState expose more parameters for customizing search spaces and evolutionary algorithms. The next tutorial will cover customizing search spaces in more detail.\n",
    "\n",
    "The TPOTClassifier and TPOTRegressor set default parameters for the TPOTEstimator for Classification and Regression.\n",
    "In the future, a metalearner will be used to predict the best values for a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tpot2.TPOTEstimatorSteadyState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpot2\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "\n",
    "graph_search_space = tpot2.search_spaces.pipelines.GraphPipeline(\n",
    "    root_search_space= tpot2.config.get_search_space([\"KNeighborsClassifier\", \"LogisticRegression\", \"DecisionTreeClassifier\"]),\n",
    "    leaf_search_space = tpot2.config.get_search_space(\"selectors\"), \n",
    "    inner_search_space = tpot2.config.get_search_space([\"transformers\"]),\n",
    "    max_size = 10,\n",
    ")\n",
    "\n",
    "est = tpot2.TPOTEstimatorSteadyState( \n",
    "                            search_space = graph_search_space,\n",
    "                            scorers=['roc_auc_ovr'], #scorers can be a list of strings or a list of scorers. These get evaluated during cross validation. \n",
    "                            scorers_weights=[1],\n",
    "\n",
    "                            classification=True,\n",
    "\n",
    "                            max_eval_time_seconds=15,\n",
    "                            max_time_seconds=30,\n",
    "                            verbose=2)\n",
    "\n",
    "\n",
    "scorer = sklearn.metrics.get_scorer('roc_auc_ovo')\n",
    "X, y = sklearn.datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "est.fit(X_train, y_train)\n",
    "print(scorer(est, X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipeline = est.fitted_pipeline_ # access best pipeline directly\n",
    "fitted_pipeline.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the summary of all evaluated individuals as a pandas dataframe\n",
    "est.evaluated_individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpot2\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "est = tpot2.TPOTEstimatorSteadyState( \n",
    "                            search_space = graph_search_space,\n",
    "                            scorers=['roc_auc_ovr',tpot2.objectives.complexity_scorer],\n",
    "                            scorers_weights=[1,-1],\n",
    "\n",
    "                            classification=True,\n",
    "\n",
    "                            max_eval_time_seconds=15,\n",
    "                            max_time_seconds=30,\n",
    "                            verbose=2)\n",
    "\n",
    "\n",
    "scorer = sklearn.metrics.get_scorer('roc_auc_ovo')\n",
    "X, y = sklearn.datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "est.fit(X_train, y_train)\n",
    "print(scorer(est, X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipeline = est.fitted_pipeline_ # access best pipeline directly\n",
    "fitted_pipeline.plot() #plot the best pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view the results of all evaluated individuals as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.evaluated_individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view pareto front as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.pareto_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_front = est.pareto_front\n",
    "\n",
    "#plot the pareto front of number_of_leaves_objective vs roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(pareto_front['complexity_scorer'], pareto_front['roc_auc_score'])\n",
    "plt.xlabel('complexity_scorer')\n",
    "plt.ylabel('roc_auc_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tpot2.TPOTEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpot2\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "est = tpot2.TPOTEstimator(  \n",
    "                            search_space = graph_search_space,\n",
    "                            population_size=30,\n",
    "                            generations=5,\n",
    "                            scorers=['roc_auc_ovr'], #scorers can be a list of strings or a list of scorers. These get evaluated during cross validation. \n",
    "                            scorers_weights=[1],\n",
    "                            classification=True,\n",
    "                            n_jobs=1, \n",
    "                            early_stop=5, #how many generations with no improvement to stop after\n",
    "                            \n",
    "                            #List of other objective functions. All objective functions take in an untrained GraphPipeline and return a score or a list of scores\n",
    "                            other_objective_functions= [ ],\n",
    "                            \n",
    "                            #List of weights for the other objective functions. Must be the same length as other_objective_functions. By default, bigger is better is set to True. \n",
    "                            other_objective_functions_weights=[],\n",
    "                            verbose=2)\n",
    "\n",
    "scorer = sklearn.metrics.get_scorer('roc_auc_ovo')\n",
    "X, y = sklearn.datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "est.fit(X_train, y_train)\n",
    "print(scorer(est, X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpot_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7fe1fe9ef32cd5efd76326a08046147513534f0dd2318301a1a96ae9071c1c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
